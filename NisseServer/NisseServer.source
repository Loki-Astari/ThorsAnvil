#include "Context.h"
#include "Pynt.h"

namespace TASock   = ThorsAnvil::ThorsSocket;

namespace ThorsAnvil::Nisse::Server
{

NISSE_HEADER_ONLY_INCLUDE
NisseServer::NisseServer(std::size_t workerCount)
    : jobQueue{workerCount}
    , store{}
    , eventHandler{jobQueue, store}
{}

NISSE_HEADER_ONLY_INCLUDE
void NisseServer::run(std::function<void()>&& notice)
{
    eventHandler.run(std::move(notice));
}

NISSE_HEADER_ONLY_INCLUDE
void NisseServer::stopSoft()
{
    eventHandler.stopSoft();
}

NISSE_HEADER_ONLY_INCLUDE
void NisseServer::stopHard()
{
    eventHandler.stopHard();
}

NISSE_HEADER_ONLY_INCLUDE
CoRoutine NisseServer::createStreamJob(StreamData& info)
{
    // Exceptions here will be caught
    // By the `EventHandler::addJob()` function.
    return CoRoutine
    {
        [&info, &server = *this](Yield& yield)
        {
            int socketId = info.stream.getSocket().socketId();
            Context     context{server, yield, socketId};
            // Set the socket to work asynchronously.
            TASock::Socket& streamSocket = info.stream.getSocket();

            streamSocket.setReadYield([&yield, &server, &info, socketId]()
            {
                // If yield() throws we are unwinding the stack.
                // This lambda is being called from deep inside the iostream but we want the
                // exception to propagate out of the stream, thus we set the exception bit here,
                // but if yield() does not throw put the exception mask back.
                std::ios_base::iostate e = info.stream.exceptions();
                info.stream.exceptions(std::ios::badbit);
                yield({TaskYieldState::RestoreRead, socketId});
                /*
                 * Entry at this point means that we have continued an existing calling that was waiting
                 * for data from the client. If you look at EventHandler::addJob() you will see that
                 * store.incActive() is called when this job is added, but the decrement was not called
                 * after the above yield() returned. So we need to compensate by calling decrement here.
                 */
                server.store.decActive();
                info.stream.exceptions(e);
                return true;
            });
            streamSocket.setWriteYield([&yield, &server, &info, socketId]()
            {
                // If yield() throws we are unwinding the stack.
                // This lambda is being called from deep inside the iostream but we want the
                // exception to propagate out of the stream, thus we set the exception bit here,
                // but if yield() does not throw put the exception mask back.
                std::ios_base::iostate e = info.stream.exceptions();
                info.stream.exceptions(std::ios::badbit);
                yield({TaskYieldState::RestoreWrite, socketId});
                /*
                 * Entry at this point means that we have continued an existing calling that was waiting
                 * to send data to the client. If you look at EventHandler::addJob() you will see that
                 * store.incActive() is called when this job is added, but the decrement was not called
                 * after the above yield() returned. So we need to compensate by calling decrement here.
                 */
                server.store.decActive();
                info.stream.exceptions(e);
                return true;
            });

            // Return control to the creator.
            // The next call will happen when there is data available on the file descriptor.
            // We do this as the co-routine is created outside a JobQueue context.
            // once we return a Job will be added to correctly continue the Job.
            // See Store: StateUpdateCreateStream and StateUpdateCreateServer
            yield({TaskYieldState::WaitForMore, socketId});

            // On normal sockets this does nothing.
            // ON SSL we do the SSL handshake.
            streamSocket.deferInit();

            PyntResult result = info.pynt->handleRequest(info.stream, context);
            while (result == PyntResult::More)
            {
                yield({TaskYieldState::WaitForMore, socketId});
                result = info.pynt->handleRequest(info.stream, context);
            }
            // We are all done
            // So indicate that we should tidy up state.
            yield({TaskYieldState::Remove, socketId});
        }
    };
}

NISSE_HEADER_ONLY_INCLUDE
CoRoutine NisseServer::createAcceptJob(ServerData& info)
{
    // Exceptions here will be caught
    // By the `EventHandler::addJob()` function.
    return CoRoutine
    {
        [&](Yield& yield)
        {
            int socketId = info.server.socketId();
            // Set the socket to work asynchronously.
            info.server.setYield([&yield, socketId](){yield({TaskYieldState::WaitForMore, socketId});return true;});

            // Return control to the creator.
            // The next call will happen when there is data available on the file descriptor.
            yield({TaskYieldState::WaitForMore, socketId});

            while (true)
            {
                TASock::Socket     accept = info.server.accept(TASock::Blocking::No, TASock::DeferAccept::Yes);
                if (accept.isConnected())
                {
                    // If everything worked then create a stream connection (see above)
                    // Passing the "Pynt" as the object that will handle the request.
                    // Note: The "Pynt" functionality is not run yet. The socket must be available to use.
                    eventHandler.add(TASock::SocketStream{std::move(accept)}, [&](StreamData& info){return createStreamJob(info);}, *info.pynt);
                }
                yield({TaskYieldState::WaitForMore, socketId});
            }
            // We are all done
            // So indicate that we should tidy up state.
            yield({TaskYieldState::Remove, socketId});
        }
    };
}

NISSE_HEADER_ONLY_INCLUDE
void NisseServer::listen(TASock::ServerInit&& listenerInit, Pynt& pynt)
{
    TASock::Server  server{std::move(listenerInit), TASock::Blocking::No};

    eventHandler.add(std::move(server), [&](ServerData& info){return createAcceptJob(info);}, pynt);
}
}

